{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObrvh6X37pU5sz9wyubq+G","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Save and Load models in Pytorch\n\nHere we use a simple CNN trained on the MNIST dataset to save and load its model\n\n# Imports","metadata":{"id":"IDQ0ZQJoeq6v"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms","metadata":{"id":"2rnQ7hvOeNhh","execution":{"iopub.status.busy":"2024-08-13T02:45:48.886577Z","iopub.execute_input":"2024-08-13T02:45:48.886973Z","iopub.status.idle":"2024-08-13T02:45:48.892508Z","shell.execute_reply.started":"2024-08-13T02:45:48.886941Z","shell.execute_reply":"2024-08-13T02:45:48.891378Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"tVIhuFdHevrr"}},{"cell_type":"code","source":"# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n# Hyperparameter\ninput_size = 784\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 10 \nload_model = False\n\n# Create the model\nclass CNN(nn.Module):\n  def __init__(self, in_channels = 1, num_classes = 10):  # 28x28 = 784\n    super(CNN, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1)) # 28x28\n    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)) # 14x14\n    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n    self.fc1 = nn.Linear(16*7*7, num_classes)\n\n  def forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = self.pool(x)\n    x = F.relu(self.conv2(x))\n    x = self.pool(x)\n    x = x.reshape(x.shape[0], -1)\n    x = self.fc1(x)\n    return x\n\n#  Define function to save checkpoint\ndef save_checkpoint(state, filename=\"mycheckpoint.pth.tar\"):\n    print(\"=> Saving checkpoint\")\n    torch.save(state,filename)\n    \ndef load_checkpoint(checkpoint):\n    print(\"=> Loading checkpoint\")\n    model.load_state_dict(checkpoint[\"state_dict\"])\n    optimizer.load_state_dict(checkpoint[\"optimizer\"])","metadata":{"id":"De4IB4j9ezAX","outputId":"f5ec245b-3d21-47dd-d37a-0859b37e2273","execution":{"iopub.status.busy":"2024-08-13T02:45:48.896956Z","iopub.execute_input":"2024-08-13T02:45:48.897346Z","iopub.status.idle":"2024-08-13T02:45:48.962502Z","shell.execute_reply.started":"2024-08-13T02:45:48.897309Z","shell.execute_reply":"2024-08-13T02:45:48.961606Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"$$n_{out}=\n\\lfloor\n\\frac{n_{in}+2p-k}{s}+1\n\\rfloor\n=\n\\lfloor\n\\frac{28+2-3}{1}+1\n\\rfloor\n=\n28\n$$\nwhere:\n\n$n_{in}$ : number of input features\n\n$n_{out}$ : number of output features\n\n$k$ : convolution kernel size\n\n$p$ : convolution padding size\n\n$s$ : convolution stride size","metadata":{"id":"ceXpgQ9Uyewa"}},{"cell_type":"markdown","source":"# Load Data","metadata":{"id":"NivC79aefIGV"}},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"id":"27vHygWwfKiU","outputId":"5cc9f5ad-68e5-484f-dc39-93eb6ea13208","execution":{"iopub.status.busy":"2024-08-13T02:45:48.964177Z","iopub.execute_input":"2024-08-13T02:45:48.964467Z","iopub.status.idle":"2024-08-13T02:45:49.054558Z","shell.execute_reply.started":"2024-08-13T02:45:48.964440Z","shell.execute_reply":"2024-08-13T02:45:49.053616Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"PohFFebhe2K7"}},{"cell_type":"code","source":"# Intialize NN\nmodel = CNN().to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\nif load_model:\n    load_checkpoint(torch.load(\"mycheckpoint.pth.tar\"))\n\n# Train the NN\nfor epoch in range(num_epochs):\n    # save checkpoint\n    if epoch % 3 == 0:\n        checkpoint = {\"state_dict\" : model.state_dict(),\n                     \"optimizer\" : optimizer.state_dict()}\n        save_checkpoint(checkpoint)\n    \n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Get data to device\n        data = data.to(device=device)\n        targets = targets.to(device=device)\n\n        # Forward propagation\n        scores = model(data)\n        loss = criterion(scores, targets) \n        \n        # Backward propagation\n        optimizer.zero_grad() # initialize all gradients to zero for each batch\n        loss.backward()\n\n        # Gradient descent or Adam step\n        optimizer.step()\n    \n    # Print loss of epoch\n    print(f\"Loss at epoch {epoch} was {loss:.05f}\")","metadata":{"id":"Xucyzc8Ge8RH","execution":{"iopub.status.busy":"2024-08-13T02:45:49.055695Z","iopub.execute_input":"2024-08-13T02:45:49.055990Z","iopub.status.idle":"2024-08-13T02:47:12.747035Z","shell.execute_reply.started":"2024-08-13T02:45:49.055964Z","shell.execute_reply":"2024-08-13T02:47:12.746049Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"=> Saving checkpoint\nLoss at epoch 0 was 0.02654\nLoss at epoch 1 was 0.27576\nLoss at epoch 2 was 0.05173\n=> Saving checkpoint\nLoss at epoch 3 was 0.05511\nLoss at epoch 4 was 0.01024\nLoss at epoch 5 was 0.01146\n=> Saving checkpoint\nLoss at epoch 6 was 0.09222\nLoss at epoch 7 was 0.01471\nLoss at epoch 8 was 0.00268\n=> Saving checkpoint\nLoss at epoch 9 was 0.00082\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Performance","metadata":{"id":"UvS7Go0de-yH"}},{"cell_type":"code","source":"# Check accuracy on training and test sets\ndef check_accuracy(loader, model):\n    if loader.dataset.train:\n        print(\"Checking accuracy on training data\")\n    else:\n        print(\"Checking accuracy on test data\")\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)  # scores is 64x10 and we want to know which one of those the is the maximum value, so in max: dim=1\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n    print(f'got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n\n    model.train()","metadata":{"id":"w9ZXp1PCfADg","execution":{"iopub.status.busy":"2024-08-13T02:47:12.749285Z","iopub.execute_input":"2024-08-13T02:47:12.749662Z","iopub.status.idle":"2024-08-13T02:47:12.756788Z","shell.execute_reply.started":"2024-08-13T02:47:12.749628Z","shell.execute_reply":"2024-08-13T02:47:12.755836Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"load_checkpoint(torch.load(\"mycheckpoint.pth.tar\"))\n\ncheck_accuracy(train_loader, model)\ncheck_accuracy(test_loader, model)","metadata":{"id":"hLDIDqEPrWhk","outputId":"94a9d564-477f-43db-88ca-477c4af08078","execution":{"iopub.status.busy":"2024-08-13T02:47:12.758086Z","iopub.execute_input":"2024-08-13T02:47:12.758373Z","iopub.status.idle":"2024-08-13T02:47:21.035217Z","shell.execute_reply.started":"2024-08-13T02:47:12.758343Z","shell.execute_reply":"2024-08-13T02:47:21.034298Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"=> Loading checkpoint\nChecking accuracy on training data\ngot 59425 / 60000 with accuracy 99.04\nChecking accuracy on test data\ngot 9869 / 10000 with accuracy 98.69\n","output_type":"stream"}]}]}