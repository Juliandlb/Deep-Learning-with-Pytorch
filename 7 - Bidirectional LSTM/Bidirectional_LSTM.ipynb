{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObrvh6X37pU5sz9wyubq+G","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Bidirectional Long short-term memory (BiLSTM)\n\nLong Short-Term Memory (BiLSTM) network is an extension of the standard LSTM network that improves the ability to learn from sequential data by processing it in both forward and backward directions. In a BiLSTM, two LSTM networks are used:\n\n- Forward LSTM: Processes the sequence in the normal order (from start to end).\n- Backward LSTM: Processes the sequence in the reverse order (from end to start).\n\n**How It Works**\n1. **Data Flow**:\n    - Forward Pass: The forward LSTM reads the sequence from the beginning to the end, capturing the dependencies in that direction.\n    - Backward Pass: The backward LSTM reads the sequence from the end to the beginning, capturing the dependencies in the reverse direction.\n2. **Concatenation**: The outputs of the forward and backward LSTMs are usually concatenated or combined in some way. This combined representation contains information from both directions, allowing the model to understand context from both past and future relative to each point in the sequence.\n\n\n\nSome documentation\n- [Wikipedia - LSTM](https://en.wikipedia.org/wiki/Long_short-term_memory)\n- [Pytorch - LSTM](https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html)\n\n\n# Imports","metadata":{"id":"IDQ0ZQJoeq6v"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms\n\n# Device \ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"id":"2rnQ7hvOeNhh","execution":{"iopub.status.busy":"2024-08-12T00:31:08.752718Z","iopub.execute_input":"2024-08-12T00:31:08.753050Z","iopub.status.idle":"2024-08-12T00:31:13.953678Z","shell.execute_reply.started":"2024-08-12T00:31:08.753022Z","shell.execute_reply":"2024-08-12T00:31:13.952573Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Model\nIn this application the RNN we can view the images from the MNIST dataset (28x28) as 28 time sequences with 28 features. Of course, normally we wouldn use RNN with images, there are way better architectures for this image related tasks.","metadata":{"id":"tVIhuFdHevrr"}},{"cell_type":"code","source":"# Hyperparameter\ninput_size = 28\nsequence_length = 28\nnum_layers = 2\nhidden_size = 256\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 2\n    \nclass BRNN(nn.Module):\n    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n        super(BRNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n        self.fc = nn.Linear(hidden_size*2, num_classes)\n    \n    def forward(self, x):\n        h0 = torch.zeros(self.num_layers*2 , x.size(0), self.hidden_size).to(device) # (num_layers x2 (forward and backward), N_mini_batches, hidden_size)\n        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device)\n        out, _ = self.lstm(x, (h0, c0))\n        out = self.fc(out[:,-1, :])\n        return out","metadata":{"id":"De4IB4j9ezAX","outputId":"f5ec245b-3d21-47dd-d37a-0859b37e2273","execution":{"iopub.status.busy":"2024-08-12T00:31:13.955645Z","iopub.execute_input":"2024-08-12T00:31:13.956299Z","iopub.status.idle":"2024-08-12T00:31:13.965095Z","shell.execute_reply.started":"2024-08-12T00:31:13.956271Z","shell.execute_reply":"2024-08-12T00:31:13.963939Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"# Load Data\n- MNIST: 28x28 pixels\n- When we load the dataset, the shape will be (batch_size, 1, 28, 28)","metadata":{"id":"NivC79aefIGV"}},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"id":"27vHygWwfKiU","outputId":"5cc9f5ad-68e5-484f-dc39-93eb6ea13208","execution":{"iopub.status.busy":"2024-08-12T00:31:13.966917Z","iopub.execute_input":"2024-08-12T00:31:13.967288Z","iopub.status.idle":"2024-08-12T00:31:16.871950Z","shell.execute_reply.started":"2024-08-12T00:31:13.967257Z","shell.execute_reply":"2024-08-12T00:31:16.871009Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to dataset/MNIST/raw/train-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 9912422/9912422 [00:00<00:00, 34872311.43it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to dataset/MNIST/raw/train-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 28881/28881 [00:00<00:00, 980220.86it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/train-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw/t10k-images-idx3-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 1648877/1648877 [00:00<00:00, 9598285.99it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-images-idx3-ubyte.gz to dataset/MNIST/raw\n\nDownloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\nFailed to download (trying next):\nHTTP Error 403: Forbidden\n\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\nDownloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 4542/4542 [00:00<00:00, 2450859.23it/s]","output_type":"stream"},{"name":"stdout","text":"Extracting dataset/MNIST/raw/t10k-labels-idx1-ubyte.gz to dataset/MNIST/raw\n\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"PohFFebhe2K7"}},{"cell_type":"code","source":"# Intialize NN\nmodel = BRNN(input_size, hidden_size, num_layers, num_classes).to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Train the NN\nfor epoch in range(num_epochs):\n    for batch_idx, (data, targets) in enumerate(train_loader):\n        # Get data to device\n        data = data.to(device=device).squeeze(1) #remove the dimention 1 in (Nx1x28x28)\n        targets = targets.to(device=device)\n\n        # Forward propagation\n        scores = model(data)\n        loss = criterion(scores, targets)\n\n        # Backward propagation\n        optimizer.zero_grad() # initialize all gradients to zero for each batch\n        loss.backward()\n\n        # Gradient descent or Adam step\n        optimizer.step()","metadata":{"id":"Xucyzc8Ge8RH","execution":{"iopub.status.busy":"2024-08-12T00:31:16.874485Z","iopub.execute_input":"2024-08-12T00:31:16.874963Z","iopub.status.idle":"2024-08-12T00:31:42.735232Z","shell.execute_reply.started":"2024-08-12T00:31:16.874926Z","shell.execute_reply":"2024-08-12T00:31:42.734225Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Performance","metadata":{"id":"UvS7Go0de-yH"}},{"cell_type":"code","source":"# Check accuracy on training and test sets\ndef check_accuracy(loader, model):\n    if loader.dataset.train:\n        print(\"Checking accuracy on training data\")\n    else:\n        print(\"Checking accuracy on test data\")\n    num_correct = 0\n    num_samples = 0\n    model.eval()\n\n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device).squeeze(1)\n            y = y.to(device=device)\n\n            scores = model(x)\n            _, predictions = scores.max(1)  # scores is 64x10 and we want to know which one of those the is the maximum value, so in max: dim=1\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n\n        print(f'got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n    model.train()","metadata":{"id":"w9ZXp1PCfADg","execution":{"iopub.status.busy":"2024-08-12T00:31:42.736431Z","iopub.execute_input":"2024-08-12T00:31:42.736704Z","iopub.status.idle":"2024-08-12T00:31:42.743976Z","shell.execute_reply.started":"2024-08-12T00:31:42.736679Z","shell.execute_reply":"2024-08-12T00:31:42.742899Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"check_accuracy(train_loader, model)\ncheck_accuracy(test_loader, model)","metadata":{"id":"hLDIDqEPrWhk","outputId":"94a9d564-477f-43db-88ca-477c4af08078","execution":{"iopub.status.busy":"2024-08-12T00:31:42.745254Z","iopub.execute_input":"2024-08-12T00:31:42.745652Z","iopub.status.idle":"2024-08-12T00:31:53.173855Z","shell.execute_reply.started":"2024-08-12T00:31:42.745618Z","shell.execute_reply":"2024-08-12T00:31:53.172860Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Checking accuracy on training data\ngot 58687 / 60000 with accuracy 97.81\nChecking accuracy on test data\ngot 9749 / 10000 with accuracy 97.49\n","output_type":"stream"}]}]}