{"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyObrvh6X37pU5sz9wyubq+G","include_colab_link":true},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU"},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Convolutional Neural Network (CNN)\n\nA convolutional neural network (CNN) is a regularized type of feed-forward neural network that learns features by itself via filter (or kernel) optimization. Vanishing gradients and exploding gradients, seen during backpropagation in earlier neural networks, are prevented by using regularized weights over fewer connections.\n\nFor example, for each neuron in the fully-connected layer, 10,000 weights would be required for processing an image sized 100 Ã— 100 pixels. However, applying cascaded convolution (or cross-correlation) kernels, only 25 neurons are required to process 5x5-sized tiles. Higher-layer features are extracted from wider context windows, compared to lower-layer features.\n\nSome documentation\n- [Wikipedia - CNN](https://en.wikipedia.org/wiki/Convolutional_neural_network)\n\n\n# Imports","metadata":{"id":"IDQ0ZQJoeq6v"}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nimport torchvision.datasets as datasets\nimport torchvision.transforms as transforms","metadata":{"id":"2rnQ7hvOeNhh","execution":{"iopub.status.busy":"2024-08-08T00:08:24.613300Z","iopub.execute_input":"2024-08-08T00:08:24.613744Z","iopub.status.idle":"2024-08-08T00:08:29.807935Z","shell.execute_reply.started":"2024-08-08T00:08:24.613708Z","shell.execute_reply":"2024-08-08T00:08:29.806706Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{"id":"tVIhuFdHevrr"}},{"cell_type":"code","source":"# Create the model\nclass CNN(nn.Module):\n  def __init__(self, in_channels = 1, num_classes = 10):  # 28x28 = 784\n    super(CNN, self).__init__()\n    self.conv1 = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=(3,3), stride=(1,1), padding=(1,1)) # 28x28\n    self.pool = nn.MaxPool2d(kernel_size=(2,2), stride=(2,2)) # 14x14\n    self.conv2 = nn.Conv2d(in_channels=8, out_channels=16, kernel_size=(3,3), stride=(1,1), padding=(1,1))\n    self.fc1 = nn.Linear(16*7*7, num_classes)\n\n  def forward(self, x):\n    x = F.relu(self.conv1(x))\n    x = self.pool(x)\n    x = F.relu(self.conv2(x))\n    x = self.pool(x)\n    x = x.reshape(x.shape[0], -1)\n    x = self.fc1(x)\n    return x\n\n# Check if it gives the correct shapes for some random data\nmodel = CNN()\nx = torch.rand(64, 1, 28, 28) # mini batch size x features\nprint(model(x).shape) # he hope to have the number of examples x the number of classes (64x10)\n\n# Device\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(device)\n\n# Hyperparameter\ninput_size = 784\nnum_classes = 10\nlearning_rate = 0.001\nbatch_size = 64\nnum_epochs = 5 ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"De4IB4j9ezAX","outputId":"f5ec245b-3d21-47dd-d37a-0859b37e2273","execution":{"iopub.status.busy":"2024-08-08T00:08:29.810326Z","iopub.execute_input":"2024-08-08T00:08:29.811928Z","iopub.status.idle":"2024-08-08T00:08:29.965946Z","shell.execute_reply.started":"2024-08-08T00:08:29.811882Z","shell.execute_reply":"2024-08-08T00:08:29.964844Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"torch.Size([64, 10])\ncpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"$$n_{out}=\n\\lfloor\n\\frac{n_{in}+2p-k}{s}+1\n\\rfloor\n=\n\\lfloor\n\\frac{28+2-3}{1}+1\n\\rfloor\n=\n28\n$$\nwhere:\n\n$n_{in}$ : number of input features\n\n$n_{out}$ : number of output features\n\n$k$ : convolution kernel size\n\n$p$ : convolution padding size\n\n$s$ : convolution stride size","metadata":{"id":"ceXpgQ9Uyewa"}},{"cell_type":"markdown","source":"# Load Data","metadata":{"id":"NivC79aefIGV"}},{"cell_type":"code","source":"train_dataset = datasets.MNIST(root='dataset/', train=True, transform=transforms.ToTensor(), download=True)\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataset = datasets.MNIST(root='dataset/', train=False, transform=transforms.ToTensor(), download=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"id":"27vHygWwfKiU","colab":{"base_uri":"https://localhost:8080/"},"outputId":"5cc9f5ad-68e5-484f-dc39-93eb6ea13208","execution":{"iopub.status.busy":"2024-08-08T00:10:28.383614Z","iopub.execute_input":"2024-08-08T00:10:28.385124Z","iopub.status.idle":"2024-08-08T00:10:28.538085Z","shell.execute_reply.started":"2024-08-08T00:10:28.385058Z","shell.execute_reply":"2024-08-08T00:10:28.536600Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{"id":"PohFFebhe2K7"}},{"cell_type":"code","source":"# Intialize NN\n# model = CNN(input_size=input_size, num_classes=num_classes).to(device)\nmodel = CNN().to(device)\n\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n# Train the NN\nfor epoch in range(num_epochs):\n  for batch_idx, (data, targets) in enumerate(train_loader):\n    # Get data to device\n    data = data.to(device=device)\n    targets = targets.to(device=device)\n\n    # Forward propagation\n    scores = model(data)\n    loss = criterion(scores, targets)\n\n    # Backward propagation\n    optimizer.zero_grad() # initialize all gradients to zero for each batch\n    loss.backward()\n\n    # Gradient descent or Adam step\n    optimizer.step()","metadata":{"id":"Xucyzc8Ge8RH","execution":{"iopub.status.busy":"2024-08-08T00:08:34.591434Z","iopub.execute_input":"2024-08-08T00:08:34.591870Z","iopub.status.idle":"2024-08-08T00:10:01.574109Z","shell.execute_reply.started":"2024-08-08T00:08:34.591835Z","shell.execute_reply":"2024-08-08T00:10:01.572784Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"# Performance","metadata":{"id":"UvS7Go0de-yH"}},{"cell_type":"code","source":"# Check accuracy on training and test sets\ndef check_accuracy(loader, model):\n  if loader.dataset.train:\n    print(\"Checking accuracy on training data\")\n  else:\n    print(\"Checking accuracy on test data\")\n  num_correct = 0\n  num_samples = 0\n  model.eval()\n\n  with torch.no_grad():\n    for x, y in loader:\n      x = x.to(device=device)\n      y = y.to(device=device)\n\n      scores = model(x)\n      _, predictions = scores.max(1)  # scores is 64x10 and we want to know which one of those the is the maximum value, so in max: dim=1\n      num_correct += (predictions == y).sum()\n      num_samples += predictions.size(0)\n\n    print(f'got {num_correct} / {num_samples} with accuracy {float(num_correct)/float(num_samples)*100:.2f}')\n\n  model.train()","metadata":{"id":"w9ZXp1PCfADg","execution":{"iopub.status.busy":"2024-08-08T00:10:01.575693Z","iopub.execute_input":"2024-08-08T00:10:01.576147Z","iopub.status.idle":"2024-08-08T00:10:01.586206Z","shell.execute_reply.started":"2024-08-08T00:10:01.576105Z","shell.execute_reply":"2024-08-08T00:10:01.584768Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"check_accuracy(train_loader, model)\ncheck_accuracy(test_loader, model)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hLDIDqEPrWhk","outputId":"94a9d564-477f-43db-88ca-477c4af08078","execution":{"iopub.status.busy":"2024-08-08T00:10:01.588682Z","iopub.execute_input":"2024-08-08T00:10:01.589166Z","iopub.status.idle":"2024-08-08T00:10:15.320363Z","shell.execute_reply.started":"2024-08-08T00:10:01.589123Z","shell.execute_reply":"2024-08-08T00:10:15.319152Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Checking accuracy on training data\ngot 58966 / 60000 with accuracy 98.28\nChecking accuracy on test data\ngot 9817 / 10000 with accuracy 98.17\n","output_type":"stream"}]}]}